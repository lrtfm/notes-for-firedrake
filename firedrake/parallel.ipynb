{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firedrake 中的并行计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 终端中并行执行 Firedrake 程序\n",
    "\n",
    "Firedrake 启动并行计算只需在终端中运行以下命令:\n",
    "\n",
    "```\n",
    "mpiexec -n <number-of-process> python3 /path/to/your/script.py\n",
    "```\n",
    "\n",
    "下面以求解 Poisson 方程的程序为例, 将以下代码保存为文件 `poisson.py`\n",
    "\n",
    "```python\n",
    "from firedrake import *\n",
    "\n",
    "N = 4\n",
    "test_mesh = RectangleMesh(nx=N, ny=N, Lx=1, Ly=1)\n",
    "x, y = SpatialCoordinate(test_mesh)\n",
    "f = sin(pi*x)*sin(pi*y)\n",
    "g = Constant(0)\n",
    "\n",
    "V = FunctionSpace(test_mesh, 'CG', degree=1)\n",
    "\n",
    "u, v = TrialFunction(V), TestFunction(V)\n",
    "a = inner(grad(u), grad(v))*dx\n",
    "L = inner(f, v)*dx\n",
    "\n",
    "bc = DirichletBC(V, g=g, sub_domain='on_boundary')\n",
    "\n",
    "u_h = Function(V, name='u_h')\n",
    "solve(a == L, u_h, bcs=bc)\n",
    "output = VTKFile('data/result.pvd')\n",
    "output.write(u_h)\n",
    "```\n",
    "\n",
    "若使用 2 个进程进行计算, 在激活的 Firedrake 环境中运行:\n",
    "```\n",
    "mpiexec -n 2 python3 poisson.py\n",
    "```\n",
    "\n",
    "求解结果将保存在 `data/result.pvd` 文件中. 在 `data` 目录下会生成一个 `result` 文件夹,\n",
    "计算结果保存在该文件夹中, 每个进程对应一个结果文件. `result.pvd` 文件只是这些结果文件的索引.\n",
    "\n",
    "Firedrake 使用 PETSc 的 DMPlex 来管理网格.\n",
    "在并行计算中, 计算区域会被划分为多个子区域 (默认情况下区域间有交叠),\n",
    "并分配给不同的进程, 因此每个进程的结果文件仅包含该进程对应区域的结果.\n",
    "\n",
    "<!--\n",
    "```bash\n",
    "MPICH_NO_LOCAL=1 mpiexec -n 16 -bind-to core -map-by socket python /path/to/script.py\n",
    "```\n",
    "-->\n",
    "\n",
    "### 并行时的一些注意事项\n",
    "\n",
    "\n",
    "#### 并行时的输出\n",
    "\n",
    "参考 [py/intro_utils.py](py/intro_utils.py)\n",
    "\n",
    "1. 第一个进程输出 (其他进程的调用会被忽略)\n",
    "\n",
    "   ```python\n",
    "   PETSc.Sys.Print(\"This is the message will only show once!\")\n",
    "   ```\n",
    "\n",
    "2. 多个进程同步输出\n",
    "\n",
    "   + [syncPrint](https://petsc.org/release/petsc4py/reference/petsc4py.PETSc.Sys.html#petsc4py.PETSc.Sys.syncPrint)\n",
    "   + [syncFlush](https://petsc.org/release/petsc4py/reference/petsc4py.PETSc.Sys.html#petsc4py.PETSc.Sys.syncFlush)\n",
    "\n",
    "   ```python\n",
    "   rank, size = COMM_WORLD.rank, COMM_WORLD.size\n",
    "   PETSc.Sys.syncPrint(f\"[{rank}/{size}] This is the message from rank {rank}!\")\n",
    "   if rank == 0:\n",
    "      PETSc.Sys.syncPrint(f\"[{rank}/{size}] Message from rank {rank}!\")\n",
    "   PETSc.Sys.syncFlush()\n",
    "   ```\n",
    "\n",
    "#### 仅在指定进程上运算\n",
    "\n",
    "如果需要在某个特定进程上执行某些操作或计算, 可以使用条件语句. 例如, 只在第 0 号进程上进行绘图操作:\n",
    "\n",
    "```python\n",
    "if COMM_WORLD.rank == 0:\n",
    "    triplot(...)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在 Jupyter-notebook/Jupyter-lab 中并行执行 Firedrake 代码\n",
    "\n",
    "在 Jupyter 交互环境中, 我们可以方便地对串行代码进行测试, 从而进行快速验证.\n",
    "为了在 Jupyter 环境下运行并行程序, `ipyparallel` 包提供了强大的支持,\n",
    "它能够帮助我们在 Jupyter 中验证并行代码, 同时加深我们对 Firedrake 并行机制的理解.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 安装配置 `ipyparallel`\n",
    "\n",
    "1. 激活 Firedrake 环境.\n",
    "    ```bash\n",
    "    source /path/to/firedrake/bin/activate\n",
    "    ```\n",
    "\n",
    "2. 安装 `ipyparallel`\n",
    "    \n",
    "    ```bash\n",
    "    pip install ipyparallel\n",
    "    ```\n",
    "\n",
    "3. 创建 `mpi` 配置文件 (profile)\n",
    "    \n",
    "    ```bash\n",
    "    ipython profile create --parallel --profile=mpi\n",
    "    ```\n",
    "    \n",
    "    运行此命令后，你将看到类似如下的输出\n",
    "    \n",
    "    ```bash\n",
    "    [ProfileCreate] Generating default config file: \n",
    "        PosixPath('/home/<your-user-name>/.ipython/profile_mpi/ipython_config.py')\n",
    "    [ProfileCreate] Generating default config file: \n",
    "        PosixPath('/home/<your-user-name>/.ipython/profile_mpi/ipython_kernel_config.py')\n",
    "    [ProfileCreate] Generating default config file: \n",
    "        PosixPath('/home/<your-user-name>/.ipython/profile_mpi/ipcontroller_config.py')\n",
    "    [ProfileCreate] Generating default config file: \n",
    "        PosixPath('/home/<your-user-name>/.ipython/profile_mpi/ipengine_config.py')\n",
    "    [ProfileCreate] Generating default config file: \n",
    "        PosixPath('/home/<your-user-name>/.ipython/profile_mpi/ipcluster_config.py')\n",
    "    ```\n",
    "\n",
    "4. 在文件 `.ipython/profile_mpi/ipengine_config.py` 的开头添加以下代码\n",
    "    \n",
    "    ```python\n",
    "    from firedrake import *\n",
    "    from firedrake.petsc import PETSc\n",
    "    ```\n",
    "\n",
    "5. 在 `.ipython/profile_mpi/ipcluster_config.py` 中设置默认引擎 (engines) 为 `mpi`. \n",
    "\n",
    "   可以在文件中搜索 `engine_launcher_class`, 并将其编辑为如下内容\n",
    "    \n",
    "    ```python\n",
    "    #    - sshproxy: ipyparallel.cluster.launcher.SSHProxyEngineSetLauncher\n",
    "    #    - winhpc: ipyparallel.cluster.launcher.WindowsHPCEngineSetLauncher\n",
    "    #  Default: 'ipyparallel.cluster.launcher.LocalEngineSetLauncher'\n",
    "    c.Cluster.engine_launcher_class = 'mpi'\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试 `ipyparallel`\n",
    "\n",
    "启动并连接 `Cluster`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "\n",
    "cluster = ipp.Cluster(profile=\"mpi\", n=2)\n",
    "client = cluster.start_and_connect_sync()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在配置好 `ipyparallel` 并启动集群后, 可以通过 Jupyter 中的魔法指令 `%%px` 在多个进程上并行执行代码.\n",
    "`%%px` 是 `ipyparallel` 提供的魔法命令, 能够在所有并行引擎上同时执行代码.\n",
    "`--block` 参数用于同步执行代码, 确保代码在所有进程上完成后再继续执行后续命令."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "from firedrake import *\n",
    "from firedrake.petsc import PETSc\n",
    "from mpi4py import MPI\n",
    "\n",
    "N = 4\n",
    "mesh = RectangleMesh(N, N, 1, 1)\n",
    "PETSc.Sys.Print(\"This will only show onece!\")\n",
    "\n",
    "rank, size = mesh.comm.rank, mesh.comm.size\n",
    "PETSc.Sys.syncPrint(f\"[{rank}/{size}] This is the message from rank {rank}!\")\n",
    "PETSc.Sys.syncFlush()\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 ipyparallel 观察串行和并行过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成网格并画出网格"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 串行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firedrake import *\n",
    "from firedrake.pyplot import triplot\n",
    "from firedrake.petsc import PETSc\n",
    "from mpi4py import MPI\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 4\n",
    "mesh = RectangleMesh(N, N, 1, 1)\n",
    "mesh.topology_dm.view()\n",
    "fig, axes = plt.subplots(figsize=[4, 3])\n",
    "c = triplot(mesh, axes=axes)\n",
    "xlim = axes.set_xlim([-0.1,1.1])\n",
    "ylim = axes.set_ylim([-0.1,1.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 并行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "from firedrake import *\n",
    "from firedrake.pyplot import triplot\n",
    "from firedrake.petsc import PETSc\n",
    "from mpi4py import MPI\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 4\n",
    "mesh = RectangleMesh(N, N, 1, 1)\n",
    "mesh.topology_dm.view()\n",
    "fig, axes = plt.subplots(figsize=[4, 3])\n",
    "c = triplot(mesh, axes=axes)\n",
    "xlim = axes.set_xlim([-0.1,1.1])\n",
    "ylim = axes.set_ylim([-0.1,1.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到上面并行中两个网格图是整体网格的一部分, 且有重叠部分."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义变分问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 串行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1 = VectorFunctionSpace(mesh, 'CG', 1)\n",
    "V2 = FunctionSpace(mesh, 'CG', 2)\n",
    "W = MixedFunctionSpace([V1, V2])  # W = V1*V2\n",
    "u1, u2 = TrialFunctions(W)\n",
    "v1, v2 = TestFunctions(W)\n",
    "a = dot(u1, v1)*dx + u2*v2*dx\n",
    "\n",
    "x, y = SpatialCoordinate(mesh)\n",
    "f = dot(as_vector((sin(x), cos(y))), v1)*dx + cos(y)*v2*dx\n",
    "\n",
    "bc = DirichletBC(W.sub(0), 0, 1)\n",
    "uh = Function(W)\n",
    "problem = LinearVariationalProblem(a, f, uh, bcs=bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 并行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "V1 = VectorFunctionSpace(mesh, 'CG', 1)\n",
    "V2 = FunctionSpace(mesh, 'CG', 2)\n",
    "W = MixedFunctionSpace([V1, V2])  # W = V1*V2\n",
    "u1, u2 = TrialFunctions(W)\n",
    "v1, v2 = TestFunctions(W)\n",
    "a = dot(u1, v1)*dx + u2*v2*dx\n",
    "\n",
    "x, y = SpatialCoordinate(mesh)\n",
    "f = dot(as_vector((sin(x), cos(y))), v1)*dx + cos(y)*v2*dx\n",
    "\n",
    "bc = DirichletBC(W.sub(0), 0, 1)\n",
    "uh = Function(W)\n",
    "problem = LinearVariationalProblem(a, f, uh, bcs=bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数空间维度\n",
    "\n",
    "函数空间 V1 和 V2 中的自由度, 可以通过调用函数 dim 得到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank, size = mesh.comm.rank, mesh.comm.size\n",
    "PETSc.Sys.Print(f'Number of dofs of V1: {V1.dim()}')\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] V1 Node count: {V1.node_count}; V1 Dof count: {V1.dof_count}')\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "rank, size = mesh.comm.rank, mesh.comm.size\n",
    "PETSc.Sys.Print(f'Number of dofs of V1: {V1.dim()}')\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] V1 Node count: {V1.node_count}; V1 Dof count: {V1.dof_count}')\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 节点集和自由度数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] V1: {str(V1.node_set)}')\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}]     {repr(V1.node_set)}')\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] V1: {str(V1.dof_dset)}')\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}]     {repr(V1.dof_dset)}')\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] V1: {str(V1.node_set)}')\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}]     {repr(V1.node_set)}')\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] V1: {str(V1.dof_dset)}')\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}]     {repr(V1.dof_dset)}')\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Size of Set and Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference:\n",
    "#   https://github.com/OP2/PyOP2/blob/31471a606a852aed250b05574d1fc2a2874eec31/pyop2/types/set.py#L30\n",
    "#\n",
    "# The division of set elements is:\n",
    "#\n",
    "#        [0, CORE)\n",
    "#        [CORE, OWNED)\n",
    "#        [OWNED, GHOST)\n",
    "#\n",
    "# Attribute of dof_dset\n",
    "#   core_size: Core set size.  Owned elements not touching halo elements.\n",
    "#   size: Set size, owned elements.\n",
    "#   total_size: Set size including ghost elements.\n",
    "#   sizes: (core_size, size, total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_set = V1.node_set\n",
    "msg = f'core size: {node_set.core_size}, size: {node_set.size}, total size: {node_set.total_size}'\n",
    "# another size: node_set.constrained_size\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] {msg}')\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "node_set = V1.node_set\n",
    "msg = f'core size: {node_set.core_size}, size: {node_set.size}, total size: {node_set.total_size}'\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] {msg}')\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dof_dset = V1.dof_dset\n",
    "size_msg = f'core size: {dof_dset.core_size}, size: {dof_dset.size}, total size: {dof_dset.total_size}'\n",
    "# dim: shape tuple of the values for each element, cdim: product of dim tuple\n",
    "dim_msg = f'dim: {dof_dset.dim}, cdim: {dof_dset.cdim}'\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] {size_msg}, {dim_msg}')\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "dof_dset = V1.dof_dset\n",
    "size_msg = f'core size: {dof_dset.core_size}, size: {dof_dset.size}, total size: {dof_dset.total_size}'\n",
    "# dim: shape tuple of the values for each element, cdim: product of dim tuple\n",
    "dim_msg = f'dim: {dof_dset.dim}, cdim: {dof_dset.cdim}'\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] {size_msg}, {dim_msg}')\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ISES of Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# field_ises:\n",
    "#   https://github.com/OP2/PyOP2/blob/31471a606a852aed250b05574d1fc2a2874eec31/pyop2/types/dataset.py#L145\n",
    "#   A list of PETSc ISes defining the global indices for each set in the DataSet.\n",
    "#   Used when extracting blocks from matrices for solvers.\n",
    "#\n",
    "# local_ises:\n",
    "#   A list of PETSc ISes defining the local indices for each set in the DataSet.\n",
    "#   Used when extracting blocks from matrices for assembly.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_ises_msg = f'{[_.getIndices() for _ in W.dof_dset.local_ises]}'\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] {local_ises_msg}')\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "local_ises_msg = f'{[_.getIndices() for _ in W.dof_dset.local_ises]}'\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] {local_ises_msg}')\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_ises_msg = f'{[_.getIndices() for _ in W.dof_dset.field_ises]}'\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] {field_ises_msg}')\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "field_ises_msg = f'{[_.getIndices() for _ in W.dof_dset.field_ises]}'\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] {field_ises_msg}')\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local to Global Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gitlab.com/petsc/petsc/-/blob/release/src/binding/petsc4py/src/petsc4py/PETSc/DM.pyx#L1777\n",
    "# setSection = setLocalSection\n",
    "# getSection = getLocalSection\n",
    "# setDefaultSection = setLocalSection\n",
    "# getDefaultSection = getLocalSection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [`firedrake.Halo.local_to_global_numbering`](https://github.com/firedrakeproject/firedrake/blob/ec0329f092b431e8e4c8bd7e41f6667234c9caa3/firedrake/halo.py#L117)\n",
    "2. [`firedrake.dmcommon.make_global_numbering`](https://github.com/firedrakeproject/firedrake/blob/ec0329f092b431e8e4c8bd7e41f6667234c9caa3/firedrake/cython/dmcommon.pyx#L3307)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halo = V1.dof_dset.halo\n",
    "# sf = halo.dm.getPointSF()\n",
    "# sf.view()\n",
    "halo.local_to_global_numbering\n",
    "# halo.dm.getLocalSection().view()\n",
    "# halo.dm.getGlobalSection().view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "halo = V1.dof_dset.halo\n",
    "# sf = halo.dm.getPointSF()\n",
    "# sf.view()\n",
    "halo.local_to_global_numbering\n",
    "# halo.dm.getLocalSection().view()\n",
    "# halo.dm.getGlobalSection().view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgmap:\n",
    "#   https://github.com/OP2/PyOP2/blob/31471a606a852aed250b05574d1fc2a2874eec31/pyop2/types/dataset.py#L111\n",
    "#   A PETSc LGMap mapping process-local indices to global indices\n",
    "\n",
    "[W.dof_dset.lgmap.apply(_) for _ in W.dof_dset.local_ises]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "[W.dof_dset.lgmap.apply(_) for _ in W.dof_dset.local_ises]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layout Vector of Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dof_dset.layout_vec.getSizes()\n",
    "vec_msg = f'Local Size: {dof_dset.layout_vec.getLocalSize()}, Size: {dof_dset.layout_vec.getSize()}'\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] {vec_msg}')\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "# dof_dset.layout_vec.getSizes()\n",
    "vec_msg = f'Local Size: {dof_dset.layout_vec.getLocalSize()}, Size: {dof_dset.layout_vec.getSize()}'\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] {vec_msg}')\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义 Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_jacobian_callback(X, J, appctx=None):\n",
    "    # appctx: user data\n",
    "    # X: vector (gauss value)\n",
    "    # J: mat\n",
    "    #\n",
    "    # mat reference:\n",
    "    #   https://petsc.org/main/petsc4py/reference/petsc4py.PETSc.Mat.html\n",
    "\n",
    "    PETSc.Sys.Print(\"post jacobian callback begin\")\n",
    "    rank, size = J.comm.rank, J.comm.size\n",
    "    PETSc.Sys.syncPrint(f\"  [{rank}/{size}] appctx: {appctx}\")\n",
    "    PETSc.Sys.syncFlush()\n",
    "    # J.setValueLocal(i, j, 1, PETSc.InsertMode.ADD_VALUES)\n",
    "    # J.assemble()\n",
    "    PETSc.Sys.Print(\"post jacobian callback end\")\n",
    "\n",
    "\n",
    "def post_function_callback(X, F, appctx=None):\n",
    "    # appctx: user data\n",
    "    # X: vector (gauss value)\n",
    "    # F: vector\n",
    "    #\n",
    "    # vec reference:\n",
    "    #   https://petsc.org/main/petsc4py/reference/petsc4py.PETSc.Vec.html\n",
    "\n",
    "    PETSc.Sys.Print(\"post function callback begin\")\n",
    "    PETSc.Sys.syncPrint(f\"  [{rank}/{size}] appctx: {appctx}\")\n",
    "    PETSc.Sys.syncFlush()\n",
    "    PETSc.Sys.Print(\"post function callback end\")\n",
    "\n",
    "appctx = {\n",
    "    'mesh': mesh,\n",
    "    'msg': 'The msg from appctx'\n",
    "}\n",
    "solver = LinearVariationalSolver(problem,\n",
    "                                 post_jacobian_callback=partial(post_jacobian_callback, appctx=appctx),\n",
    "                                 post_function_callback=partial(post_function_callback, appctx=appctx))\n",
    "solver.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "def post_jacobian_callback(X, J, appctx=None):\n",
    "    # appctx: user data\n",
    "    # X: vector (gauss value)\n",
    "    # J: mat\n",
    "    #\n",
    "    # mat reference:\n",
    "    #   https://petsc.org/main/petsc4py/reference/petsc4py.PETSc.Mat.html\n",
    "\n",
    "    PETSc.Sys.Print(\"post jacobian callback begin\")\n",
    "    rank, size = J.comm.rank, J.comm.size\n",
    "    PETSc.Sys.syncPrint(f\"  [{rank}/{size}] appctx: {appctx}\")\n",
    "    PETSc.Sys.syncFlush()\n",
    "    # J.setValueLocal(i, j, 1, PETSc.InsertMode.ADD_VALUES)\n",
    "    # J.assemble()\n",
    "    PETSc.Sys.Print(\"post jacobian callback end\")\n",
    "\n",
    "\n",
    "def post_function_callback(X, F, appctx=None):\n",
    "    # appctx: user data\n",
    "    # X: vector (gauss value)\n",
    "    # F: vector\n",
    "    #\n",
    "    # vec reference:\n",
    "    #   https://petsc.org/main/petsc4py/reference/petsc4py.PETSc.Vec.html\n",
    "\n",
    "    PETSc.Sys.Print(\"post function callback begin\")\n",
    "    PETSc.Sys.syncPrint(f\"  [{rank}/{size}] appctx: {appctx}\")\n",
    "    PETSc.Sys.syncFlush()\n",
    "    PETSc.Sys.Print(\"post function callback end\")\n",
    "\n",
    "appctx = {\n",
    "    'mesh': mesh,\n",
    "    'msg': 'The msg from appctx'\n",
    "}\n",
    "solver = LinearVariationalSolver(problem,\n",
    "                                 post_jacobian_callback=partial(post_jacobian_callback, appctx=appctx),\n",
    "                                 post_function_callback=partial(post_function_callback, appctx=appctx))\n",
    "solver.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context of the Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = solver._ctx\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] Assembler: {ctx._assembler_jac}')\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] Matrix Size: {ctx._jac.petscmat.getSizes()}')\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --block\n",
    "ctx = solver._ctx\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] Assembler: {ctx._assembler_jac}')\n",
    "PETSc.Sys.syncPrint(f'[{rank}/{size}] Matrix Size: {ctx._jac.petscmat.getSizes()}')\n",
    "PETSc.Sys.syncFlush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix 组装\n",
    "\n",
    "矩阵存储分配相关函数\n",
    "\n",
    "1. Firedrake method: [ExplicitMatrixAssembler.allocate](https://github.com/firedrakeproject/firedrake/blob/ec0329f092b431e8e4c8bd7e41f6667234c9caa3/firedrake/assemble.py#L1307)\n",
    "\n",
    "2. PyOp2 class: [Sparsity](https://github.com/OP2/PyOP2/blob/31471a606a852aed250b05574d1fc2a2874eec31/pyop2/types/mat.py#L26)\n",
    "\n",
    "3. PyOp2 function: [build_sparsity](https://github.com/OP2/PyOP2/blob/31471a606a852aed250b05574d1fc2a2874eec31/pyop2/sparsity.pyx#L121)\n",
    "\n",
    "4. PyOp2 class: [Mat](https://github.com/OP2/PyOP2/blob/31471a606a852aed250b05574d1fc2a2874eec31/pyop2/types/mat.py#L554)\n",
    "\n",
    "更多组装细节请看 [矩阵组装内核](./kernels.ipynb)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
